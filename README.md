# VCR: Video representation for Contextual Retrieval
Authors: Oron Nir, Idan Vidra, Avi Neeman, Barak Kinarti, Ariel Shamir

![Our Topics-Map](https://github.com/oronnir/VCR/blob/main/ArchiveExplorer-04.png?raw=true "Our Topics-Map")

## Abstract
Streamlining content discovery within media archives requires integrating advanced data representations and effective visualization techniques for clear communication of video topics to users. The proposed system addresses the challenge of efficiently navigating large video collections by exploiting a fusion of visual, audio, and textual features to accurately index and categorize video content through a text-based method. Additionally, semantic embeddings are employed to provide contextually relevant information and recommendations to users, resulting in an intuitive and engaging exploratory experience over our topics ontology map using OpenAI GPT-4.

## Demo video
[![arXiv](https://img.shields.io/badge/YouTube-FF0000?style=for-the-badge&logo=youtube&logoColor=white)](https://www.youtube.com/watch?v=28_3ntFX2Hs)

## News and Updates
Our paper was accepted for IRESP 2024 - please find it here: [![arXiv](https://img.shields.io/badge/arXiv-2402.07466-b31b1b.svg)](https://arxiv.org/abs/2402.07466)

## Comming up soon
* Demo video
* The TED dataset
* Code

![Our Topics-Map](https://github.com/oronnir/VCR/blob/main/MethodArchitecture.png?raw=true "Text-based Video Embedding")


```
@misc{nir2024vcr,
      title={VCR: Video representation for Contextual Retrieval}, 
      author={Oron Nir and Idan Vidra and Avi Neeman and Barak Kinarti and Ariel Shamir},
      year={2024},
      eprint={2402.07466},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}
```
